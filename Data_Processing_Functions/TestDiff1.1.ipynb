{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "organizational-intent",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "function 'full_info_from_reflections' not found",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"<ipython-input-1-037bb379962f>\"\u001b[0m, line \u001b[0;32m33\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    lib.full_info_from_reflections.argtypes= [CrystalHandle, ctypes.c_bool, ctypes.c_float, c_int_array_2, c_int_array, c_int_array]\n",
      "  File \u001b[0;32m\"C:\\Users\\Marc\\Anaconda3\\lib\\ctypes\\__init__.py\"\u001b[0m, line \u001b[0;32m377\u001b[0m, in \u001b[0;35m__getattr__\u001b[0m\n    func = self.__getitem__(name)\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Marc\\Anaconda3\\lib\\ctypes\\__init__.py\"\u001b[1;36m, line \u001b[1;32m382\u001b[1;36m, in \u001b[1;35m__getitem__\u001b[1;36m\u001b[0m\n\u001b[1;33m    func = self._FuncPtr((name_or_ordinal, self))\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m\u001b[1;31m:\u001b[0m function 'full_info_from_reflections' not found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#from TestDiff.ipynb import Crystal\n",
    "import numpy as np\n",
    "import ctypes\n",
    "\n",
    "\n",
    "#Wrapper\n",
    "\n",
    "#path to the dll\n",
    "lib = ctypes.CDLL(\"E:/Arxius varis/PhD/2nd_year/Code/Diffraction_pattern_simulation_E_V/Library/difftool_1.1/diffTools.dll\")\n",
    "#lib = ctypes.cdll.LoadLibrary(\"E:/Arxius varis/PhD/2nd_year/Code/Diffraction_pattern_simulation_E_V/Library/difftool/diffTools.dll\")\n",
    "\n",
    "\n",
    "CrystalHandle = ctypes.POINTER(ctypes.c_char)\n",
    "c_int_array = np.ctypeslib.ndpointer(dtype=np.int32, ndim=1, flags='C_CONTIGUOUS')\n",
    "c_int_array_2 = np.ctypeslib.ndpointer(dtype=np.int32, ndim=2, flags='C_CONTIGUOUS')\n",
    "\n",
    "\n",
    "lib.createCrystal.argtypes = [ctypes.c_char_p]\n",
    "lib.createCrystal.restype = CrystalHandle\n",
    "\n",
    "lib.calc_d.argtypes = [CrystalHandle, ctypes.c_bool, ctypes.c_float]\n",
    "lib.calc_d.restypes = ctypes.c_int\n",
    "\n",
    "lib.FindZA.argtypes = [CrystalHandle, ctypes.c_float, ctypes.c_float, ctypes.c_float, ctypes.c_float]\n",
    "lib.FindZA.restype = ctypes.c_int\n",
    "\n",
    "lib.GetZA.argtypes = [CrystalHandle, ctypes.c_int, c_int_array]\n",
    "lib.GetZA.restype = None\n",
    "\n",
    "lib.destroyCrystal.argtypes = [CrystalHandle]\n",
    "lib.destroyCrystal.restype = None\n",
    "\n",
    "lib.full_info_from_reflections.argtypes= [CrystalHandle, ctypes.c_bool, ctypes.c_float, c_int_array_2, c_int_array, c_int_array]\n",
    "lib.full_info_from_reflections.restype = None\n",
    "\n",
    "\n",
    "\n",
    "class Crystal:\n",
    "    \n",
    "    def __init__(self,name):\n",
    "        self.instance = lib.createCrystal(name)\n",
    "    \n",
    "    def __del__(self):\n",
    "        lib.destroyCrystal(self.instance)\n",
    "    \n",
    "    def getZA(self,N):\n",
    "        n = ctypes.c_int(N)\n",
    "        hkl = np.empty(3, dtype=np.int32)\n",
    "        lib.GetZA(self.instance,n,hkl)\n",
    "        return hkl\n",
    "    \n",
    "    def Diff(self,flag,D):\n",
    "        min_d = ctypes.c_float(D)\n",
    "        flagd=ctypes.c_bool(flag)\n",
    "        N = lib.calc_d(self.instance,flagd,min_d)\n",
    "        return N\n",
    "    \n",
    "    def FindZA(self,D1,D2,ANG,TOL):\n",
    "        d1=ctypes.c_float(D1)\n",
    "        d2=ctypes.c_float(D2)\n",
    "        ang=ctypes.c_float(ANG)\n",
    "        tol=ctypes.c_float(TOL)\n",
    "        self.n = lib.FindZA(self.instance,d1,d2,ang,tol)\n",
    "        return self.n\n",
    "    \n",
    "    def full_info_from_reflections(self, flag, D):\n",
    "        min_d = ctypes.c_float(D)\n",
    "        flagd=ctypes.c_bool(flag) \n",
    "        N = lib.calc_d(self.instance,flagd,min_d)\n",
    "        \n",
    "        hkl_s=np.empty((N,3), dtype=np.int32)\n",
    "        distances=np.empty(N, dtype=np.int32)\n",
    "        F_factors=np.empty(N, dtype=np.int32)\n",
    "        \n",
    "        lib.full_info_from_reflections(self.instance,flagd, min_d,hkl_s,distances, F_factors)\n",
    "        \n",
    "        return hkl_s, distances, F_factors\n",
    "   \n",
    "import ctypes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.measure as measure\n",
    "import cv2\n",
    "import torch\n",
    "import stemtool\n",
    "import hyperspy.api as hs\n",
    "from Diffraction_simulation_ZA_finding import Crystal\n",
    "import time\n",
    "\n",
    "def Find_percentage_of_thresholded(FFT_image, threshold):\n",
    "    FFT_image[FFT_image<=threshold]=0\n",
    "    percentage_of_tresholded=np.count_nonzero(FFT_image.ravel())/len(FFT_image.ravel())\n",
    "    return percentage_of_tresholded\n",
    "\n",
    "def Threshold_given_percentage(FFT_image, percentage):\n",
    "    y_pixs,x_pixs=np.shape(FFT_image)\n",
    "    n_int_pixs=int(round(percentage*y_pixs*x_pixs))\n",
    "    FFT_ravel=np.sort(np.ravel(FFT_image))[::-1]\n",
    "    threshold=FFT_ravel[n_int_pixs]\n",
    "    return threshold\n",
    "\n",
    "def mpfit_Distance(FFT_image,FOV):\n",
    "    mpfit_model=[[-2.87175127e-11],\n",
    "                     [ 8.11320079e-09],\n",
    "                     [-8.18658056e-07],\n",
    "                     [ 3.33222163e-05],\n",
    "                     [-2.02745223e-04],\n",
    "                     [-2.26140649e-02],\n",
    "                     [ 5.95346985e-01],\n",
    "                     [-7.69005862e-01]]\n",
    "    # without the averages\n",
    "    mpfit_model_c=[[-3.46636981e-11],\n",
    "                   [ 1.00423053e-08],\n",
    "                   [-1.06223267e-06],\n",
    "                   [ 4.84860471e-05],\n",
    "                   [-6.82330526e-04],\n",
    "                   [-1.58450088e-02],\n",
    "                   [ 5.79540436e-01],\n",
    "                   [-1.10510783e+00]]\n",
    "    #set the working limits of the model\n",
    "    if FOV >=30:\n",
    "        mpfit_dist=np.array([40])\n",
    "    else:\n",
    "        \n",
    "        fov_vals=np.array([FOV**7,FOV**6,FOV**5,FOV**4,FOV**3,FOV**2,FOV**1,1])\n",
    "        mpfit_dist=np.e**np.dot(fov_vals,mpfit_model)\n",
    "        mpfit_dist=np.e**np.dot(fov_vals,mpfit_model_c)\n",
    "     \n",
    "    #Adjustments depending on the sizze of the image\n",
    "    if np.shape(FFT_image)[0]==2048:\n",
    "        mpfit_dist=mpfit_dist*1.30\n",
    "    elif np.shape(FFT_image)[0]<256:\n",
    "        mpfit_dist=mpfit_dist*1.55     \n",
    "    elif np.shape(FFT_image)[0]==256:\n",
    "        mpfit_dist=mpfit_dist*1.55     \n",
    "    elif np.shape(FFT_image)[0]==1024:\n",
    "        mpfit_dist=mpfit_dist*1.05\n",
    "    elif np.shape(FFT_image)[0]==512:\n",
    "        mpfit_dist=mpfit_dist*1.15\n",
    "    else:\n",
    "        mpfit_dist=mpfit_dist*1.15\n",
    "        \n",
    "    return mpfit_dist[0]\n",
    "\n",
    "def FFT_threshold(FOV):\n",
    "    FFT_thresh_model=[[-1.01291174e-11],\n",
    "                          [ 2.88297492e-09],\n",
    "                          [-3.01778444e-07],\n",
    "                          [ 1.44327587e-05],\n",
    "                          [-3.23378617e-04],\n",
    "                          [ 3.61163733e-03],\n",
    "                          [-3.72515413e-02],\n",
    "                          [-1.96361805e-01]]\n",
    "    # without the averages\n",
    "    FFT_thresh_model_c=[[ 1.54099057e-12],\n",
    "                        [-6.56354380e-10],\n",
    "                        [ 1.05878669e-07],\n",
    "                        [-8.09680716e-06],\n",
    "                        [ 2.96148198e-04],\n",
    "                        [-4.30807411e-03],\n",
    "                        [ 1.81389577e-03],\n",
    "                        [-2.45698182e-01]]\n",
    "    #set the working limits of the model\n",
    "    if FOV >=80:\n",
    "        FFT_thresh=np.array([0.6])\n",
    "    else:\n",
    "                \n",
    "        fov_vals=np.array([FOV**7,FOV**6,FOV**5,FOV**4,FOV**3,FOV**2,FOV**1,1])\n",
    "        FFT_thresh=np.e**np.dot(fov_vals,FFT_thresh_model)\n",
    "        FFT_thresh=np.e**np.dot(fov_vals,FFT_thresh_model_c)\n",
    "      \n",
    "    \n",
    "    return FFT_thresh[0]\n",
    "\n",
    "def FFT_percentage(FFT_image,FOV):\n",
    "    FFT_perc_model=[[-3.00411834e-11],\n",
    "                        [ 1.17313244e-08],\n",
    "                        [-1.81232383e-06],\n",
    "                        [ 1.40635117e-04],\n",
    "                        [-5.76020214e-03],\n",
    "                        [ 1.20704617e-01],\n",
    "                        [-1.20113823e+00],\n",
    "                        [-2.14024711e+00]]\n",
    "    # without the averages\n",
    "    FFT_perc_model_c=[[ 1.38602821e-11],\n",
    "                      [-2.46874956e-09],\n",
    "                      [-1.63526870e-08],\n",
    "                      [ 2.67725990e-05],\n",
    "                      [-1.91230990e-03],\n",
    "                      [ 5.28789844e-02],\n",
    "                      [-6.40863899e-01],\n",
    "                      [-3.71037505e+00]]\n",
    "    #set the working limits of the model\n",
    "    if FOV >=110:\n",
    "        FFT_perc=np.array([0.00025])  #In case it is too much for higher FOVs, just delete this and keep the FFT_perc_model for all ranges\n",
    "    # elif FOV <3:\n",
    "    #     FFT_perc=np.array([0.01])\n",
    "    else:\n",
    "        \n",
    "        \n",
    "        fov_vals=np.array([FOV**7,FOV**6,FOV**5,FOV**4,FOV**3,FOV**2,FOV**1,1])\n",
    "        FFT_perc=np.e**np.dot(fov_vals,FFT_perc_model)\n",
    "        FFT_perc=np.e**np.dot(fov_vals,FFT_perc_model_c)        \n",
    "        \n",
    "        if FOV <4.5:\n",
    "            FFT_perc=FFT_perc*(10**(np.log(128/np.shape(FFT_image)[0])/np.log(4)))\n",
    "        elif FOV >=4.5 and FOV <=20 :\n",
    "            FFT_perc=FFT_perc*(10**(np.log(512/np.shape(FFT_image)[0])/np.log(4)))\n",
    "        else:\n",
    "            FFT_perc=FFT_perc*(10**(np.log(2048/np.shape(FFT_image)[0])/np.log(4)))\n",
    "    \n",
    "    #Adjustments depending on the sizze of the image\n",
    "    if np.shape(FFT_image)[0]<256:\n",
    "        FFT_perc=FFT_perc*0.25\n",
    "    elif np.shape(FFT_image)[0]==256:\n",
    "        FFT_perc=FFT_perc*0.45  \n",
    "    elif np.shape(FFT_image)[0]==512:\n",
    "        FFT_perc=FFT_perc*0.55\n",
    "    elif np.shape(FFT_image)[0]==1024:\n",
    "        FFT_perc=FFT_perc*0.80    \n",
    "    else:\n",
    "        FFT_perc=FFT_perc*0.80\n",
    "        \n",
    "    return FFT_perc[0]\n",
    "\n",
    "def FFT_hyperparams(FFT_image,FOV):\n",
    "    #Return, in order, the mpfit dist, the threshold, and the percentage\n",
    "    \n",
    "    mpfit_dist=mpfit_Distance(FFT_image,FOV)\n",
    "    FFT_thresh=FFT_threshold(FOV)\n",
    "    FFT_perc=FFT_percentage(FFT_image,FOV)\n",
    "    \n",
    "    return mpfit_dist,FFT_thresh,FFT_perc\n",
    "\n",
    "\n",
    "\n",
    "def FFT_calibration(hyperspy_2D_signal):\n",
    "    fft_shifted = hyperspy_2D_signal.fft(shift=True)\n",
    "    \n",
    "    FFT_calibration=fft_shifted.axes_manager['x'].scale\n",
    "    FFT_pixels=fft_shifted.axes_manager['x'].size\n",
    "    FFT_units=fft_shifted.axes_manager['x'].units\n",
    "    \n",
    "    return FFT_calibration,FFT_pixels,FFT_units\n",
    "    \n",
    "\n",
    "def Spot_coord_To_d_spacing_indiv(coords, FFT_calibration, FFT_pixels):\n",
    "    \n",
    "    (y_max, x_max)=coords\n",
    "\n",
    "    FFT_distance_point_x=np.abs(x_max-int(FFT_pixels/2))*FFT_calibration\n",
    "    FFT_distance_point_y=np.abs(y_max-int(FFT_pixels/2))*FFT_calibration\n",
    "    \n",
    "    FFT_distance_total=np.sqrt(FFT_distance_point_x**2+FFT_distance_point_y**2)\n",
    "    \n",
    "    \n",
    "    d_spacing_spot=1/FFT_distance_total\n",
    "    \n",
    "    return d_spacing_spot\n",
    "\n",
    "\n",
    "\n",
    "def Spot_coord_To_d_spacing_vect(coord_vects, FFT_calibration, FFT_pixels):\n",
    "    y_vects=coord_vects[:,0]    \n",
    "    x_vects=coord_vects[:,1] \n",
    "\n",
    "    FFT_distance_point_x=np.abs(x_vects-int(FFT_pixels/2))*FFT_calibration\n",
    "    FFT_distance_point_y=np.abs(y_vects-int(FFT_pixels/2))*FFT_calibration\n",
    "    \n",
    "    FFT_distance_total=np.sqrt(FFT_distance_point_x**2+FFT_distance_point_y**2)\n",
    "    \n",
    "    \n",
    "    d_spacing_spot=1/FFT_distance_total\n",
    "    \n",
    "    return d_spacing_spot\n",
    "\n",
    "\n",
    "def Spot_coord_To_Angles_to_X_indiv(coords,FFT_pixels):\n",
    "    \n",
    "    (y_max, x_max)=coords\n",
    "    \n",
    "    cont_dist=x_max-int(FFT_pixels/2)\n",
    "    opp_dist=int(FFT_pixels/2)-y_max\n",
    "    \n",
    "    angles_to_X=np.arctan2(opp_dist,cont_dist)*180/np.pi\n",
    "    \n",
    "    return angles_to_X\n",
    "\n",
    "\n",
    "def Spot_coord_To_Angles_to_X_vect(coord_vects,FFT_pixels):\n",
    "    y_vects=coord_vects[:,0]    \n",
    "    x_vects=coord_vects[:,1] \n",
    "    \n",
    "    cont_dist=x_vects-int(FFT_pixels/2)\n",
    "    opp_dist=int(FFT_pixels/2)-y_vects\n",
    "    \n",
    "    angles_to_X=np.arctan2(opp_dist,cont_dist)*180/np.pi\n",
    "    \n",
    "    return angles_to_X\n",
    "\n",
    "\n",
    "def Ensure_Center_Diff(distances_array, angles_to_x_array):\n",
    "    \n",
    "    #define hyperparameter, that should not be very modifyable, as it is the \n",
    "    #maximum interplanar distance to consider, in nm, let us say d_int > 1-1.5nm\n",
    "    #as no plane should be  bigger than 1-1.5nm. Let us say 1.5 to include 1/2 indices \n",
    "    \n",
    "    #what we do is remove these spots from the array, as they should not be considered\n",
    "    #either in angle or distance, so this already solves unwanted spots at a very small frequency or high dist.\n",
    "    \n",
    "    distances_array_c=distances_array[distances_array<=1.5]\n",
    "    angles_to_x_array_c=angles_to_x_array[distances_array<=1.5]\n",
    "   \n",
    "    return distances_array_c, angles_to_x_array_c\n",
    "\n",
    "\n",
    "\n",
    "#Hyperparameters\n",
    "gauss_blur_filter_size=(5,5)  #size of smoothing filter, go to line to change sigma\n",
    "downscaling_factor=1 #for trials, n factor of downsampling size of image\n",
    "FFT_thresholding=0.5  #value above which the pixels are kept\n",
    "st_distance=30 #distance parameter in the Stem tool method\n",
    "FFT_thresholdingG=0.6 #value above which the pixels are kept, in the gaussian filtered FFT\n",
    "window_size=128  #window size of the sliding windows\n",
    "np.random.seed(int(time.time()))\n",
    "\n",
    "#dm3 loading, and calibration extraction\n",
    "imagedm3=hs.load(r'E:\\Arxius varis\\PhD\\2nd_year\\Code\\trial_images\\dm3_atomic_resolution\\GeQW2.dm3')\n",
    "meta1=imagedm3.metadata\n",
    "meta2=imagedm3.original_metadata.export('parameters')\n",
    "\n",
    "\n",
    "\n",
    "x_calibration=imagedm3.axes_manager['x'].scale\n",
    "y_calibration=imagedm3.axes_manager['y'].scale\n",
    "\n",
    "x_pixels=imagedm3.axes_manager['x'].size\n",
    "y_pixels=imagedm3.axes_manager['y'].size\n",
    "\n",
    "x_units=imagedm3.axes_manager['x'].units\n",
    "y_units=imagedm3.axes_manager['y'].units\n",
    "\n",
    "\n",
    "#FFT calibration\n",
    "\n",
    "FFT_calibration,FFT_pixels,FFT_units=FFT_calibration(imagedm3)\n",
    "\n",
    "\n",
    "imagearray=np.asarray(imagedm3)\n",
    "image=imagearray\n",
    "\n",
    "plt.imshow(image, cmap=plt.cm.gray, vmin=image.min(), vmax=image.max())\n",
    "plt.show()\n",
    "#First standarisation of the image for filtering/blurring it with gaussian filter\n",
    "image_st=(image-np.min(image))/np.max(image-np.min(image))\n",
    "\n",
    "\n",
    "\n",
    "#Application of Gaussian filter for denoising\n",
    "\n",
    "\n",
    "denoised_image=cv2.GaussianBlur(image_st, gauss_blur_filter_size, 1)\n",
    "\n",
    "\n",
    "#Second standarisation of the image after filtering/blurring it with gaussian filter\n",
    "\n",
    "image_st=(denoised_image-np.min(denoised_image))/np.max(denoised_image-np.min(denoised_image))\n",
    "\n",
    "#Print histogram\n",
    "\n",
    "\n",
    "\n",
    "#For sake of evaluation, better work with an image with less pixels, as only the consecutive pixel evaluation would take\n",
    "#approximately 6 hours to run for a big region of 250.000 pixels in total.\n",
    "\n",
    "#Then downsample the image and upsample it posteriorly \n",
    "#We select a max pooling method to keep track of the brighter elements and this way keep a higher contrast\n",
    "\n",
    "\n",
    "ds_image=measure.block_reduce(image_st, block_size=tuple(np.int32(downscaling_factor*np.ones(len(np.shape(image_st))))), func=np.mean, cval=0)\n",
    "\n",
    "#and standarise it again to ensure 0-1 values\n",
    "\n",
    "ds_image_st=(ds_image-np.min(ds_image))/np.max(ds_image-np.min(ds_image))\n",
    "\n",
    "\n",
    "# take the fft of the image\n",
    "fft_image_w_background = np.fft.fftshift(np.log(np.fft.fft2(ds_image_st)))\n",
    "fft_abs_image_background = np.abs(fft_image_w_background)\n",
    "\n",
    "# apply the filter\n",
    "fft_abs_image_background2=np.copy(fft_abs_image_background)\n",
    "fft_abs_image_backgroundc=np.copy(fft_abs_image_background)\n",
    "\n",
    "\n",
    "fft_abs_image_backgroundc=(fft_abs_image_backgroundc-np.min(fft_abs_image_backgroundc))/np.max(fft_abs_image_backgroundc-np.min(fft_abs_image_backgroundc))\n",
    "\n",
    "\n",
    "fft_abs_image_background2=(fft_abs_image_background2-np.min(fft_abs_image_background2))/np.max(fft_abs_image_background2-np.min(fft_abs_image_background2))\n",
    "\n",
    "\n",
    "fft_abs_image_background2=cv2.GaussianBlur(fft_abs_image_background2, gauss_blur_filter_size, 1)\n",
    "fft_abs_image_background2=(fft_abs_image_background2-np.min(fft_abs_image_background2))/np.max(fft_abs_image_background2-np.min(fft_abs_image_background2))\n",
    "\n",
    "\n",
    "#trial with original FFT\n",
    "#fft_abs_image_background2=fft_abs_image_backgroundc\n",
    "\n",
    "#Automatic hyperparameter finding\n",
    "fov=np.shape(fft_abs_image_background2)[0]*y_calibration\n",
    "print('fov',fov)\n",
    "st_distance,_,FFT_perc=FFT_hyperparams(fft_abs_image_background2,fov)\n",
    "print('mpfit',st_distance,'perc',FFT_perc )\n",
    "FFT_thresholdingG=Threshold_given_percentage(fft_abs_image_background2, FFT_perc)\n",
    "print('fft_threhs',FFT_thresholdingG)\n",
    "\n",
    "\n",
    "print('STEM Tool based method (2D Gaussians)')\n",
    "\n",
    "center_difractogram=(int(FFT_pixels/2), int(FFT_pixels/2))\n",
    "\n",
    "print('ST gaussian FFT')\n",
    "twodfit_blur=stemtool.afit.peaks_vis(fft_abs_image_background2, dist=st_distance, thresh=FFT_thresholdingG, imsize=(15, 15))\n",
    "\n",
    "d_distances=Spot_coord_To_d_spacing_vect(twodfit_blur, FFT_calibration, FFT_pixels)\n",
    "\n",
    "angles_to_x=Spot_coord_To_Angles_to_X_vect(twodfit_blur,FFT_pixels)\n",
    "\n",
    "print(d_distances)\n",
    "\n",
    "print(angles_to_x)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "refined_distances, refined_angles_to_x=Ensure_Center_Diff(d_distances, angles_to_x)\n",
    "\n",
    "#set the values of distances in angstroms\n",
    "refined_distances=refined_distances*10    \n",
    "\n",
    "#prepare the distances to be analysed\n",
    "\n",
    "#start by taking a random spot\n",
    "distance1=np.random.choice(refined_distances)\n",
    "#starting with the first spot at approx 90 degrees from x axis could be nice as well\n",
    "\n",
    "indexdist1=np.argmin(np.abs(refined_distances-distance1)) \n",
    "distances2=np.delete(refined_distances, indexdist1)\n",
    "angles=np.abs(refined_angles_to_x-refined_angles_to_x[indexdist1])\n",
    "angles=np.delete(angles, indexdist1)\n",
    "\n",
    "\n",
    "#Watch out in case angles need to be between 0 and 180 to limit this, although it should work as well.\n",
    "#Maybe take the center of diffraction out after computing to avoid confusions, as it is not a diffracted spot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Diffraction simulation of a given cell\n",
    "\n",
    "\n",
    "Ge_cell = Crystal(b'E:/Arxius varis/PhD/2nd_year/Code/unit_cells/Ge.uce')\n",
    "\n",
    "min_d=0.5    #minimum interplanar distance computed in the diffraction\n",
    "forbidden = False  #Include (True) or not (False) the forbbiden reflections\n",
    "\n",
    "n = Ge_cell.Diff(forbidden,min_d)\n",
    "print(\"Calculated \",n ,\"reflections\")\n",
    "\n",
    "tol=0.05   #tolerance: how different from theoretical values the previous values can be to get good output\n",
    "\n",
    "ZA_list=[]\n",
    "\n",
    "for d2, angle in zip(distances2,angles):\n",
    "    print(\"Between distance 1 = {:.3f} A and distance 2 = {:.3f} A, there are {:.3f} degrees\".format(distance1, d2, angle))\n",
    "\n",
    "\n",
    "    n = Ge_cell.FindZA(distance1,d2,angle,tol)\n",
    "    print(\"Found \",n,\"possible Zone Axes\")\n",
    "    \n",
    "    #Include or not the possibility to output high index axes\n",
    "    high_index=False\n",
    "    \n",
    "    if n==0:\n",
    "        ZA=None\n",
    "    else:\n",
    "        if high_index==True:\n",
    "            ZA=Ge_cell.getZA(0)\n",
    "        else:\n",
    "            for index in range(n):\n",
    "                ZA=Ge_cell.getZA(index)\n",
    "                if np.sum(np.abs(ZA))< 10: #if sum of indices is higher than 10 is already high indexes\n",
    "                    break\n",
    "                else:\n",
    "                    ZA=None\n",
    "                    continue\n",
    "        \n",
    "    \n",
    "    print(ZA)\n",
    "    \n",
    "    if type(ZA)==type(None):\n",
    "        ZA_list.append(ZA)\n",
    "    else:\n",
    "        ZA_list.append(np.sort(np.abs(ZA)))\n",
    "\n",
    "\n",
    "ZA_list_index=[index for index in ZA_list if type(index)!=type(None)]\n",
    "ZA_arr_index=np.asarray(ZA_list_index)\n",
    "\n",
    "\n",
    "temp_array_ZA = np.ascontiguousarray(ZA_arr_index).view(np.dtype((np.void, ZA_arr_index.dtype.itemsize * ZA_arr_index.shape[1])))\n",
    "_, idx,counts = np.unique(temp_array_ZA, return_index=True, return_counts=True)\n",
    "\n",
    "ZA_unique = np.unique(temp_array_ZA).view(ZA_arr_index.dtype).reshape(-1, ZA_arr_index.shape[1])\n",
    "\n",
    "\n",
    "ZA_final=ZA_unique[np.argmax(counts)]\n",
    "print('Found ZA:', ZA_final)\n",
    "\n",
    "\n",
    "\n",
    "hkl_s, distances, F_factors=Ge_cell.full_info_from_reflections(forbidden,min_d)\n",
    "\n",
    "print(hkl_s)\n",
    "print(distances)\n",
    "print(F_factors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-distinction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
